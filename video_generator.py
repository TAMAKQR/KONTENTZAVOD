"""–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Replicate API"""
import asyncio
import json
import logging
from typing import Optional, List, Dict
import replicate
from replicate import Client
from config import REPLICATE_API_TOKEN, OPENAI_API_KEY
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class VideoGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Replicate API"""
    
    def __init__(self):
        self.replicate_token = REPLICATE_API_TOKEN
        self.replicate_client = Client(api_token=REPLICATE_API_TOKEN)
        self.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # –ú–æ–¥–µ–ª–∏
        self.models = {
            "kling": "kwaivgi/kling-v2.5-turbo-pro",
            "sora": "openai/sora-2",
            "veo": "google/veo-3.1-fast"
        }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_params = {
            "kling": {
                "duration": 5,
                "aspect_ratio": "16:9",
                "negative_prompt": ""
            },
            "sora": {
                "duration": 10,
                "aspect_ratio": "16:9"
            },
            "veo": {
                "duration": 8,
                "aspect_ratio": "16:9"
            }
        }

    async def enhance_prompt_with_gpt(self, prompt: str, num_scenes: int = 3, duration_per_scene: int = 5) -> Dict:
        """
        –£–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–º—Ç —á–µ—Ä–µ–∑ GPT-4 –∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Å—Ü–µ–Ω—ã
        
        Args:
            prompt: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º—Ç
            num_scenes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω
            duration_per_scene: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            Dict —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º—Ç–æ–º –∏ —Å—Ü–µ–Ω–∞–º–∏
        """
        try:
            system_message = f"""You are a professional video script writer. Analyze the user's prompt and break it down into exactly {num_scenes} connected scenes.

IMPORTANT: Return ONLY valid JSON, nothing else. No markdown, no explanations.

Return JSON with this exact structure:
{{
    "enhanced_prompt": "enhanced overall video description",
    "scenes": [
        {{
            "id": 1,
            "prompt": "detailed scene 1 prompt",
            "duration": {duration_per_scene},
            "atmosphere": "scene atmosphere"
        }}
    ]
}}

Rules:
- Each scene must flow smoothly to the next
- Each scene prompt must be 1-2 sentences, detailed and specific
- Duration: {duration_per_scene} seconds for all scenes
- Atmosphere: cinematic, dramatic, calm, energetic, etc
- Create exactly {num_scenes} scenes
- Scenes must connect logically and visually"""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": f"Create {num_scenes} connected video scenes from this prompt: {prompt}"}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
            response_text = response.choices[0].message.content.strip()
            logger.info(f"üìù GPT –æ—Ç–≤–µ—Ç: {response_text[:200]}...")
            
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–µ—Ä–Ω—É—Ç –≤ markdown)
            if "```json" in response_text:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
            elif "```" in response_text:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
            else:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.error(f"‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ: {response_text}")
                raise ValueError("JSON not found in response")
            
            json_str = response_text[start_idx:end_idx]
            logger.info(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π JSON: {json_str[:100]}...")
            
            result = json.loads(json_str)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            if "scenes" not in result:
                raise ValueError("'scenes' key not found in response")
            
            if not isinstance(result["scenes"], list):
                raise ValueError("'scenes' must be a list")
            
            if len(result["scenes"]) != num_scenes:
                logger.warning(f"‚ö†Ô∏è GPT —Å–æ–∑–¥–∞–ª {len(result['scenes'])} —Å—Ü–µ–Ω –≤–º–µ—Å—Ç–æ {num_scenes}")
            
            logger.info(f"‚úÖ GPT —É–ª—É—á—à–∏–ª –ø—Ä–æ–º—Ç, —Å–æ–∑–¥–∞–Ω–æ {len(result['scenes'])} —Å—Ü–µ–Ω")
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
            logger.info(f"üåç –ü–µ—Ä–µ–≤–æ–¥—É —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫...")
            result = await self._translate_scenes_to_russian(result)
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ GPT: {e}")
            logger.error(f"‚ùå –î–µ—Ç–∞–ª–∏: {str(e)}")
            # –§–æ–ª–ª–±–∞–∫ - –ø—Ä–æ—Å—Ç–æ —Å–æ–∑–¥–∞–µ–º —Å—Ü–µ–Ω—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
            logger.info(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É—é —Ñ–æ–ª–ª–±–∞–∫: —Ä–∞–∑–¥–µ–ª—è—é –ø—Ä–æ–º—Ç –Ω–∞ {num_scenes} —Å—Ü–µ–Ω—ã")
            return {
                "enhanced_prompt": prompt,
                "scenes": [
                    {
                        "id": i + 1,
                        "prompt": f"{prompt} - –ß–∞—Å—Ç—å {i + 1}",
                        "duration": 5,
                        "atmosphere": "cinematic"
                    }
                    for i in range(num_scenes)
                ]
            }
    
    async def _translate_scenes_to_russian(self, scenes_result: Dict) -> Dict:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        
        Args:
            scenes_result: Dict —Å–æ —Å—Ü–µ–Ω–∞–º–∏ –∏ enhanced_prompt
            
        Returns:
            Dict —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º–∏ —Å—Ü–µ–Ω–∞–º–∏
        """
        try:
            scenes = scenes_result.get("scenes", [])
            if not scenes:
                return scenes_result
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            scenes_to_translate = []
            for scene in scenes:
                scenes_to_translate.append({
                    "id": scene.get("id"),
                    "prompt": scene.get("prompt"),
                    "atmosphere": scene.get("atmosphere", "")
                })
            
            translation_request = f"""Translate the following video scenes to Russian. 
Keep the same JSON structure. Translate ONLY the "prompt" and "atmosphere" fields.

Scenes to translate:
{json.dumps(scenes_to_translate, ensure_ascii=False, indent=2)}

Return ONLY valid JSON with translated content, nothing else."""
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a professional translator from English to Russian. Translate video scene descriptions accurately and naturally."},
                    {"role": "user", "content": translation_request}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            response_text = response.choices[0].message.content.strip()
            logger.info(f"üåç GPT –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç–≤–µ—Ç: {response_text[:150]}...")
            
            # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ü–µ–Ω—ã
            if "```json" in response_text:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
            elif "```" in response_text:
                start_idx = response_text.find('[')
                end_idx = response_text.rfind(']') + 1
                if start_idx == -1:
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
            else:
                start_idx = response_text.find('[')
                end_idx = response_text.rfind(']') + 1
                if start_idx == -1:
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ü–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ")
                return scenes_result
            
            translated_text = response_text[start_idx:end_idx]
            translated_list = json.loads(translated_text)
            
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
            if not isinstance(translated_list, list):
                translated_list = [translated_list]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Å—Ü–µ–Ω–∞–º
            for i, scene in enumerate(scenes):
                if i < len(translated_list):
                    translated = translated_list[i]
                    if "prompt" in translated:
                        scene["prompt"] = translated["prompt"]
                    if "atmosphere" in translated:
                        scene["atmosphere"] = translated["atmosphere"]
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º enhanced_prompt –µ—Å–ª–∏ –µ—Å—Ç—å
            if "enhanced_prompt" in scenes_result:
                enhanced = scenes_result["enhanced_prompt"]
                enhanced_translation = await self._translate_text(enhanced)
                scenes_result["enhanced_prompt"] = enhanced_translation
            
            logger.info(f"‚úÖ –°—Ü–µ–Ω—ã –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
            return scenes_result
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Å—Ü–µ–Ω: {e}")
            logger.warning(f"‚ö†Ô∏è –í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞")
            return scenes_result
    
    async def _translate_text(self, text: str) -> str:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            
        Returns:
            –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a professional translator. Translate to Russian accurately."},
                    {"role": "user", "content": f"Translate to Russian: {text}"}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return text

    async def generate_scene(
        self,
        prompt: str,
        model: str = "kling",
        duration: int = 5,
        aspect_ratio: str = "16:9",
        start_image_url: Optional[str] = None,
        scene_number: int = 1
    ) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ü–µ–Ω—É –≤–∏–¥–µ–æ
        
        Args:
            prompt: –ü—Ä–æ–º—Ç –¥–ª—è –≤–∏–¥–µ–æ
            model: –ú–æ–¥–µ–ª—å (kling, sora, veo)
            duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            aspect_ratio: –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
            start_image_url: URL –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞ (–¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏)
            scene_number: –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        try:
            model_id = self.models.get(model, self.models["kling"])
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            input_params = {
                "prompt": prompt,
                "duration": duration,
                "aspect_ratio": aspect_ratio
            }
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {model}")
            logger.info(f"   –ü—Ä–æ–º—Ç: {prompt[:60]}...")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: duration={duration}s, aspect_ratio={aspect_ratio}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if model == "kling":
                input_params["negative_prompt"] = ""
                if start_image_url:
                    input_params["start_image"] = start_image_url
                    logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è start_image –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏")
            elif model == "veo":
                if start_image_url:
                    input_params["last_frame_url"] = start_image_url
                    logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è last_frame_url –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏")
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –Ω–∞ Replicate API...")
            logger.info(f"   Model ID: {model_id}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π replicate.run –≤ –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            output = await loop.run_in_executor(
                None,
                lambda: self.replicate_client.run(
                    model_id,
                    input=input_params
                )
            )
            
            output_str = str(output) if output else "None"
            logger.info(f"‚úÖ –°—Ü–µ–Ω–∞ {scene_number}: –í–∏–¥–µ–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            logger.info(f"   URL: {output_str[:80]}...")
            
            return {
                "status": "success",
                "video_url": output_str,
                "model": model,
                "duration": duration,
                "scene_number": scene_number
            }
            
        except Exception as e:
            logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {scene_number}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ!")
            logger.error(f"   –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"   –¢–∏–ø: {type(e).__name__}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
            return {
                "status": "error",
                "error": str(e),
                "model": model,
                "scene_number": scene_number
            }

    async def generate_multiple_scenes(
        self,
        scenes: List[Dict],
        model: str = "kling",
        start_image_url: Optional[str] = None,
        scene_image_urls: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ü–µ–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        
        Args:
            scenes: –°–ø–∏—Å–æ–∫ —Å—Ü–µ–Ω —Å –ø—Ä–æ–º—Ç–∞–º–∏
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            start_image_url: URL –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞ (–¥–ª—è –ø–µ—Ä–≤–æ–π —Å—Ü–µ–Ω—ã, –µ—Å–ª–∏ –Ω–µ—Ç scene_image_urls)
            scene_image_urls: –°–ø–∏—Å–æ–∫ URLs –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ start_image_url)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        logger.info(f"üé¨ –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é {len(scenes)} —Å—Ü–µ–Ω —á–µ—Ä–µ–∑ {model}...")
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –¢–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è –ö–ê–ñ–î–û–ô —Å—Ü–µ–Ω—ã
        if scene_image_urls:
            logger.info(f"üì∏ –ü–µ—Ä–µ–¥–∞—é {len(scene_image_urls)} —Ñ–æ—Ç–æ - –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã")
            if len(scene_image_urls) != len(scenes):
                logger.warning(f"‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ ({len(scene_image_urls)}) != –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω ({len(scenes)})")
        
        tasks = []
        
        for i, scene in enumerate(scenes):
            # –í—ã–±–∏—Ä–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è —ç—Ç–æ–π —Å—Ü–µ–Ω—ã
            scene_image = None
            if scene_image_urls and i < len(scene_image_urls):
                scene_image = scene_image_urls[i]
            elif start_image_url and i == 0:
                scene_image = start_image_url
            
            if scene_image:
                logger.info(f"üì∏ –°—Ü–µ–Ω–∞ {i+1}: –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ")
            
            task = self.generate_scene(
                prompt=scene["prompt"],
                model=model,
                duration=scene.get("duration", 5),
                aspect_ratio=scene.get("aspect_ratio", "16:9"),
                start_image_url=scene_image,  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è –≠–¢–û–ô —Å—Ü–µ–Ω—ã (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–π!)
                scene_number=i + 1
            )
            tasks.append(task)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –í–°–ï —Å—Ü–µ–Ω—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (asyncio.gather)
        # –≠—Ç–æ –ù–ê–ú–ù–û–ì–û –±—ã—Å—Ç—Ä–µ–µ —á–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ!
        logger.info(f"‚ö° –û—Ç–ø—Ä–∞–≤–ª—è—é {len(tasks)} –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –Ω–∞ Replicate API...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –æ—à–∏–±–∫–∏
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {i + 1}: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {result}")
                processed_results.append({
                    "status": "error",
                    "error": str(result),
                    "scene_number": i + 1
                })
            else:
                processed_results.append(result)
        
        logger.info(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(processed_results)} —Å—Ü–µ–Ω")
        return processed_results

    async def generate_photo(
        self,
        prompt: str,
        model: str = "google/nano-banana",
        reference_url: Optional[str] = None,
        scene_number: int = 1
    ) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ google/nano-banana
        
        Args:
            prompt: –ü—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ
            model: –ú–æ–¥–µ–ª—å (google/nano-banana –∏–ª–∏ google/imagen-4)
            reference_url: URL —Ñ–æ—Ç–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
            scene_number: –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        try:
            logger.info(f"üì∏ –°—Ü–µ–Ω–∞ {scene_number}: –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ {model}...")
            logger.info(f"   –ü—Ä–æ–º—Ç: {prompt[:60]}...")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            input_params = {
                "prompt": prompt,
            }
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
            if reference_url and model == "google/nano-banana":
                input_params["image"] = reference_url
                input_params["strength"] = 0.7  # –°–∏–ª–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
                logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è referencias –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏")
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –Ω–∞ Replicate API...")
            logger.info(f"   Model: {model}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π replicate.run –≤ –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            output = await loop.run_in_executor(
                None,
                lambda: self.replicate_client.run(
                    model,
                    input=input_params
                )
            )
            
            output_str = str(output) if output else "None"
            logger.info(f"‚úÖ –°—Ü–µ–Ω–∞ {scene_number}: –§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            logger.info(f"   URL: {output_str[:80]}...")
            
            return {
                "status": "success",
                "photo_url": output_str,
                "model": model,
                "scene_number": scene_number
            }
            
        except Exception as e:
            logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {scene_number}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ!")
            logger.error(f"   –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"   –¢–∏–ø: {type(e).__name__}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
            return {
                "status": "error",
                "error": str(e),
                "model": model,
                "scene_number": scene_number
            }