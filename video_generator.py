"""–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Replicate API"""
import asyncio
import json
import logging
from typing import Optional, List, Dict
import replicate
from replicate import Client
from config import REPLICATE_API_TOKEN, OPENAI_API_KEY
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)


class VideoGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ —á–µ—Ä–µ–∑ Replicate API"""
    
    def __init__(self):
        self.replicate_token = REPLICATE_API_TOKEN
        self.replicate_client = Client(api_token=REPLICATE_API_TOKEN)
        self.openai_client = AsyncOpenAI(api_key=OPENAI_API_KEY)
        
        # –ú–æ–¥–µ–ª–∏
        self.models = {
            "kling": "kwaivgi/kling-v2.5-turbo-pro",
            "sora": "openai/sora-2",
            "veo": "google/veo-3.1-fast"
        }
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        self.default_params = {
            "kling": {
                "duration": 5,
                "aspect_ratio": "16:9",
                "negative_prompt": ""
            },
            "sora": {
                "duration": 10,
                "aspect_ratio": "16:9"
            },
            "veo": {
                "duration": 8,
                "aspect_ratio": "16:9"
            }
        }

    async def enhance_prompt_with_gpt(self, prompt: str, num_scenes: int = 3, duration_per_scene: int = 5) -> Dict:
        """
        –£–ª—É—á—à–∞–µ—Ç –ø—Ä–æ–º—Ç —á–µ—Ä–µ–∑ GPT-4 –∏ —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ –†–ê–ó–ù–´–ï —Å—Ü–µ–Ω—ã
        
        Args:
            prompt: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–º—Ç
            num_scenes: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω
            duration_per_scene: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            
        Returns:
            Dict —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –ø—Ä–æ–º—Ç–æ–º –∏ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ —Å—Ü–µ–Ω–∞–º–∏
        """
        try:
            # üìù –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ò–ù–°–¢–†–£–ö–¶–ò–Ø –¥–ª—è GPT
            system_message = """You are a professional video director. Create unique, visually distinct scenes from a product/concept description.

RULES:
1. Return ONLY valid JSON, no markdown or explanations
2. Create DIFFERENT angles/moments for each scene (not repetition)
3. Each scene must have a unique visual perspective
4. Keep prompts concise but vivid (1-2 sentences)

REQUIRED JSON FORMAT - Return valid JSON array like this:
[
  {"id": 1, "prompt": "scene description with unique angle/moment", "duration": 5, "atmosphere": "cinematic"},
  {"id": 2, "prompt": "different perspective or progression", "duration": 5, "atmosphere": "dramatic"}
]"""

            user_message = f"""Break this into {num_scenes} VISUALLY DIFFERENT scenes (not parts of same scene):

CONCEPT: {prompt}

IMPORTANT: 
- Scene 1: Opening/approach view
- Scene 2: Detail/close-up or different angle  
- Scene 3+: Progression or new perspective
- Each must show something new, not repeat

Create {num_scenes} unique scenes with {duration_per_scene}sec each."""

            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.8,
                max_tokens=2000
            )
            
            response_text = response.choices[0].message.content.strip()
            logger.info(f"üìù GPT –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –¥–ª–∏–Ω–∞: {len(response_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ü–∞—Ä—Å–∏–º JSON - –∏—â–µ–º –º–∞—Å—Å–∏–≤
            start_idx = response_text.find('[')
            end_idx = response_text.rfind(']') + 1
            
            if start_idx == -1 or end_idx == 0:
                # –ï—Å–ª–∏ –Ω–µ—Ç –º–∞—Å—Å–∏–≤–∞, –∏—â–µ–º –æ–±—ä–µ–∫—Ç
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
                
                if start_idx == -1 or end_idx == 0:
                    logger.error(f"‚ùå JSON –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ: {response_text[:200]}")
                    raise ValueError("JSON not found in response")
                
                # –ï—Å–ª–∏ –æ–¥–∏–Ω –æ–±—ä–µ–∫—Ç - –æ–±–æ—Ä–∞—á–∏–≤–∞–µ–º –≤ –º–∞—Å—Å–∏–≤
                json_str = response_text[start_idx:end_idx]
                result = {"scenes": [json.loads(json_str)]}
            else:
                json_str = response_text[start_idx:end_idx]
                scenes_list = json.loads(json_str)
                result = {
                    "enhanced_prompt": prompt,
                    "scenes": scenes_list if isinstance(scenes_list, list) else [scenes_list]
                }
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
            if "scenes" not in result:
                result["scenes"] = result if isinstance(result, list) else [result]
            
            if not isinstance(result["scenes"], list):
                result["scenes"] = [result["scenes"]]
            
            # –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º —Ä–æ–≤–Ω–æ num_scenes —Å—Ü–µ–Ω
            actual_scenes = result.get("scenes", [])
            if len(actual_scenes) < num_scenes:
                logger.warning(f"‚ö†Ô∏è GPT —Å–æ–∑–¥–∞–ª {len(actual_scenes)} –≤–º–µ—Å—Ç–æ {num_scenes}, –¥–æ–ø–æ–ª–Ω—è—é...")
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ü–µ–Ω—ã –∫–∞–∫ –≤–∞—Ä–∏–∞—Ü–∏–∏
                for i in range(len(actual_scenes), num_scenes):
                    actual_scenes.append({
                        "id": i + 1,
                        "prompt": f"{prompt} - —É–≥–æ–ª {i + 1}",
                        "duration": duration_per_scene,
                        "atmosphere": "cinematic"
                    })
            elif len(actual_scenes) > num_scenes:
                actual_scenes = actual_scenes[:num_scenes]
            
            result["scenes"] = actual_scenes
            
            # –ü—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º ID –∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            for i, scene in enumerate(result["scenes"]):
                scene["id"] = i + 1
                scene["duration"] = duration_per_scene
                if "atmosphere" not in scene:
                    scene["atmosphere"] = "cinematic"
            
            logger.info(f"‚úÖ GPT —Å–æ–∑–¥–∞–ª {len(result['scenes'])} —Å—Ü–µ–Ω")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ü–µ–Ω—ã –î–û –ø–µ—Ä–µ–≤–æ–¥–∞
            for i, scene in enumerate(result['scenes']):
                logger.info(f"   üìù –°—Ü–µ–Ω–∞ {i+1} (–î–û –ø–µ—Ä–µ–≤–æ–¥–∞): '{scene.get('prompt', '')}'")
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
            logger.info(f"üåç –ü–µ—Ä–µ–≤–æ–¥—É —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π...")
            result = await self._translate_scenes_to_russian(result)
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ü–µ–Ω—ã –ü–û–°–õ–ï –ø–µ—Ä–µ–≤–æ–¥–∞
            for i, scene in enumerate(result['scenes']):
                logger.info(f"   üá∑üá∫ –°—Ü–µ–Ω–∞ {i+1} (–ü–û–°–õ–ï –ø–µ—Ä–µ–≤–æ–¥–∞): '{scene.get('prompt', '')}'")
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
            logger.error(f"‚ùå –û—Ç–≤–µ—Ç: {response_text[:300]}")
            raise
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ GPT: {e}")
            logger.error(f"‚ùå –î–µ—Ç–∞–ª–∏: {str(e)}")
            
            # ‚ö†Ô∏è –õ—É—á—à–∏–π —Ñ–æ–ª–ª–±–∞–∫ - —Å–æ–∑–¥–∞–µ–º –†–ê–ó–ù–´–ï —Å—Ü–µ–Ω—ã –≤—Ä—É—á–Ω—É—é
            logger.info(f"‚ö†Ô∏è –°–æ–∑–¥–∞—é {num_scenes} –†–ê–ó–ù–´–• —Å—Ü–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")
            scenes = [
                {
                    "id": 1,
                    "prompt": f"{prompt} - –æ–±—â–∏–π –ø–ª–∞–Ω",
                    "duration": duration_per_scene,
                    "atmosphere": "cinematic"
                },
                {
                    "id": 2,
                    "prompt": f"{prompt} - –∫—Ä—É–ø–Ω—ã–π –ø–ª–∞–Ω –¥–µ—Ç–∞–ª–µ–π",
                    "duration": duration_per_scene,
                    "atmosphere": "dramatic"
                }
            ]
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ—Ç—å—é –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å—Ü–µ–Ω—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if num_scenes > 2:
                scenes.append({
                    "id": 3,
                    "prompt": f"{prompt} - —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∫—É—Ä—Å",
                    "duration": duration_per_scene,
                    "atmosphere": "cinematic"
                })
            
            for i in range(3, num_scenes):
                scenes.append({
                    "id": i + 1,
                    "prompt": f"{prompt} - –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–∞ {i}",
                    "duration": duration_per_scene,
                    "atmosphere": "cinematic"
                })
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å–æ–∑–¥–∞–Ω–Ω—É—é —Å—Ü–µ–Ω—É
            for scene in scenes:
                logger.info(f"   ‚úÖ –°—Ü–µ–Ω–∞ {scene['id']}: '{scene['prompt']}'")
            
            return {
                "enhanced_prompt": prompt,
                "scenes": scenes
            }
    
    async def _translate_scenes_to_russian(self, scenes_result: Dict) -> Dict:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å–µ —Å—Ü–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        
        Args:
            scenes_result: Dict —Å–æ —Å—Ü–µ–Ω–∞–º–∏ –∏ enhanced_prompt
            
        Returns:
            Dict —Å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–º–∏ —Å—Ü–µ–Ω–∞–º–∏
        """
        try:
            scenes = scenes_result.get("scenes", [])
            if not scenes:
                return scenes_result
            
            logger.info(f"üåç _translate_scenes_to_russian: –ø–æ–ª—É—á–∏–ª {len(scenes)} —Å—Ü–µ–Ω")
            for i, scene in enumerate(scenes):
                prompt_text = scene.get('prompt', '')[:100]
                logger.info(f"   INPUT –°—Ü–µ–Ω–∞ {i+1}: '{prompt_text}'")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            scenes_to_translate = []
            for scene in scenes:
                scenes_to_translate.append({
                    "id": scene.get("id"),
                    "prompt": scene.get("prompt"),
                    "atmosphere": scene.get("atmosphere", "")
                })
            
            translation_request = f"""Translate the following video scenes to Russian. 
Keep the same JSON structure. Translate ONLY the "prompt" and "atmosphere" fields.

Scenes to translate:
{json.dumps(scenes_to_translate, ensure_ascii=False, indent=2)}

Return ONLY valid JSON with translated content, nothing else."""
            
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a professional translator from English to Russian. Translate video scene descriptions accurately and naturally."},
                    {"role": "user", "content": translation_request}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            response_text = response.choices[0].message.content.strip()
            logger.info(f"üåç GPT –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç–≤–µ—Ç: {response_text[:150]}...")
            
            # –ü–∞—Ä—Å–∏–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ü–µ–Ω—ã
            if "```json" in response_text:
                start_idx = response_text.find('{')
                end_idx = response_text.rfind('}') + 1
            elif "```" in response_text:
                start_idx = response_text.find('[')
                end_idx = response_text.rfind(']') + 1
                if start_idx == -1:
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
            else:
                start_idx = response_text.find('[')
                end_idx = response_text.rfind(']') + 1
                if start_idx == -1:
                    start_idx = response_text.find('{')
                    end_idx = response_text.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Å—Ü–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ")
                return scenes_result
            
            translated_text = response_text[start_idx:end_idx]
            translated_list = json.loads(translated_text)
            
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ —Å–ø–∏—Å–æ–∫, –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ø–∏—Å–æ–∫
            if not isinstance(translated_list, list):
                translated_list = [translated_list]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã –∫ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º —Å—Ü–µ–Ω–∞–º
            for i, scene in enumerate(scenes):
                if i < len(translated_list):
                    translated = translated_list[i]
                    if "prompt" in translated:
                        scene["prompt"] = translated["prompt"]
                    if "atmosphere" in translated:
                        scene["atmosphere"] = translated["atmosphere"]
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º enhanced_prompt –µ—Å–ª–∏ –µ—Å—Ç—å
            if "enhanced_prompt" in scenes_result:
                enhanced = scenes_result["enhanced_prompt"]
                enhanced_translation = await self._translate_text(enhanced)
                scenes_result["enhanced_prompt"] = enhanced_translation
            
            logger.info(f"‚úÖ –°—Ü–µ–Ω—ã –ø–µ—Ä–µ–≤–µ–¥–µ–Ω—ã –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫")
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞
            for i, scene in enumerate(scenes):
                prompt_text = scene.get('prompt', '')[:100]
                logger.info(f"   OUTPUT –°—Ü–µ–Ω–∞ {i+1}: '{prompt_text}'")
            
            return scenes_result
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Å—Ü–µ–Ω: {e}")
            logger.warning(f"‚ö†Ô∏è –í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Å—Ü–µ–Ω—ã –±–µ–∑ –ø–µ—Ä–µ–≤–æ–¥–∞")
            return scenes_result
    
    async def _translate_text(self, text: str) -> str:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            
        Returns:
            –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "You are a professional translator. Translate to Russian accurately."},
                    {"role": "user", "content": f"Translate to Russian: {text}"}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ —Ç–µ–∫—Å—Ç–∞: {e}")
            return text

    async def generate_scene(
        self,
        prompt: str,
        model: str = "kling",
        duration: int = 5,
        aspect_ratio: str = "16:9",
        start_image_url: Optional[str] = None,
        scene_number: int = 1
    ) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–¥–Ω—É —Å—Ü–µ–Ω—É –≤–∏–¥–µ–æ
        
        Args:
            prompt: –ü—Ä–æ–º—Ç –¥–ª—è –≤–∏–¥–µ–æ
            model: –ú–æ–¥–µ–ª—å (kling, sora, veo)
            duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            aspect_ratio: –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Å—Ç–æ—Ä–æ–Ω
            start_image_url: URL –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞ (–¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏)
            scene_number: –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        try:
            model_id = self.models.get(model, self.models["kling"])
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
            input_params = {
                "prompt": prompt,
                "duration": duration,
                "aspect_ratio": aspect_ratio
            }
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞—é –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è {model}")
            logger.info(f"   –ü—Ä–æ–º—Ç: {prompt[:60]}...")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: duration={duration}s, aspect_ratio={aspect_ratio}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            if model == "kling":
                input_params["negative_prompt"] = ""
                if start_image_url:
                    input_params["start_image"] = start_image_url
                    logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è start_image –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏")
            elif model == "veo":
                if start_image_url:
                    input_params["last_frame_url"] = start_image_url
                    logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è last_frame_url –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏")
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –Ω–∞ Replicate API...")
            logger.info(f"   Model ID: {model_id}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π replicate.run –≤ –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            output = await loop.run_in_executor(
                None,
                lambda: self.replicate_client.run(
                    model_id,
                    input=input_params
                )
            )
            
            output_str = str(output) if output else "None"
            logger.info(f"‚úÖ –°—Ü–µ–Ω–∞ {scene_number}: –í–∏–¥–µ–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            logger.info(f"   URL: {output_str[:80]}...")
            
            return {
                "status": "success",
                "video_url": output_str,
                "model": model,
                "duration": duration,
                "scene_number": scene_number
            }
            
        except Exception as e:
            logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {scene_number}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤–∏–¥–µ–æ!")
            logger.error(f"   –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"   –¢–∏–ø: {type(e).__name__}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
            return {
                "status": "error",
                "error": str(e),
                "model": model,
                "scene_number": scene_number
            }

    async def generate_multiple_scenes(
        self,
        scenes: List[Dict],
        model: str = "kling",
        start_image_url: Optional[str] = None,
        scene_image_urls: Optional[List[str]] = None
    ) -> List[Dict]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ü–µ–Ω –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        
        Args:
            scenes: –°–ø–∏—Å–æ–∫ —Å—Ü–µ–Ω —Å –ø—Ä–æ–º—Ç–∞–º–∏
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            start_image_url: URL –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ —Ñ—Ä–µ–π–º–∞ (–¥–ª—è –ø–µ—Ä–≤–æ–π —Å—Ü–µ–Ω—ã, –µ—Å–ª–∏ –Ω–µ—Ç scene_image_urls)
            scene_image_urls: –°–ø–∏—Å–æ–∫ URLs –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞–¥ start_image_url)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        """
        logger.info(f"üé¨ –ù–∞—á–∏–Ω–∞—é –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é {len(scenes)} —Å—Ü–µ–Ω —á–µ—Ä–µ–∑ {model}...")
        
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –¢–µ–ø–µ—Ä—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è –ö–ê–ñ–î–û–ô —Å—Ü–µ–Ω—ã
        if scene_image_urls:
            logger.info(f"üì∏ –ü–µ—Ä–µ–¥–∞—é {len(scene_image_urls)} —Ñ–æ—Ç–æ - –ø–æ –æ–¥–Ω–æ–º—É –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ü–µ–Ω—ã")
            if len(scene_image_urls) != len(scenes):
                logger.warning(f"‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ ({len(scene_image_urls)}) != –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ü–µ–Ω ({len(scenes)})")
        
        tasks = []
        
        for i, scene in enumerate(scenes):
            # –í—ã–±–∏—Ä–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è —ç—Ç–æ–π —Å—Ü–µ–Ω—ã
            scene_image = None
            if scene_image_urls and i < len(scene_image_urls):
                scene_image = scene_image_urls[i]
            elif start_image_url and i == 0:
                scene_image = start_image_url
            
            if scene_image:
                logger.info(f"üì∏ –°—Ü–µ–Ω–∞ {i+1}: –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ —Ñ–æ—Ç–æ")
            
            task = self.generate_scene(
                prompt=scene["prompt"],
                model=model,
                duration=scene.get("duration", 5),
                aspect_ratio=scene.get("aspect_ratio", "16:9"),
                start_image_url=scene_image,  # ‚úÖ –ü–µ—Ä–µ–¥–∞–µ–º —Ñ–æ—Ç–æ –¥–ª—è –≠–¢–û–ô —Å—Ü–µ–Ω—ã (–Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–π!)
                scene_number=i + 1
            )
            tasks.append(task)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –í–°–ï —Å—Ü–µ–Ω—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (asyncio.gather)
        # –≠—Ç–æ –ù–ê–ú–ù–û–ì–û –±—ã—Å—Ç—Ä–µ–µ —á–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ!
        logger.info(f"‚ö° –û—Ç–ø—Ä–∞–≤–ª—è—é {len(tasks)} –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –Ω–∞ Replicate API...")
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –æ—à–∏–±–∫–∏
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {i + 1}: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {result}")
                processed_results.append({
                    "status": "error",
                    "error": str(result),
                    "scene_number": i + 1
                })
            else:
                processed_results.append(result)
        
        logger.info(f"‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(processed_results)} —Å—Ü–µ–Ω")
        return processed_results

    async def generate_photo(
        self,
        prompt: str,
        model: str = "google/nano-banana",
        reference_url: Optional[str] = None,
        scene_number: int = 1
    ) -> Dict:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ google/nano-banana
        
        Args:
            prompt: –ü—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ
            model: –ú–æ–¥–µ–ª—å (google/nano-banana –∏–ª–∏ google/imagen-4)
            reference_url: URL —Ñ–æ—Ç–æ-—Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏
            scene_number: –ù–æ–º–µ—Ä —Å—Ü–µ–Ω—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º –∏–ª–∏ –æ—à–∏–±–∫–æ–π
        """
        try:
            logger.info(f"üì∏ –°—Ü–µ–Ω–∞ {scene_number}: –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ {model}...")
            logger.info(f"   –ü—Ä–æ–º—Ç: {prompt[:60]}...")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
            input_params = {
                "prompt": prompt,
            }
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ—Ñ–µ—Ä–µ–Ω—Å, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
            if reference_url and model == "google/nano-banana":
                input_params["image"] = reference_url
                input_params["strength"] = 0.7  # –°–∏–ª–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∏–ª—è —Ä–µ—Ñ–µ—Ä–µ–Ω—Å–∞
                logger.info(f"   –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è referencias –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏")
            
            logger.info(f"üé¨ –°—Ü–µ–Ω–∞ {scene_number}: –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –Ω–∞ Replicate API...")
            logger.info(f"   Model: {model}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π replicate.run –≤ –ø–æ—Ç–æ–∫–µ
            loop = asyncio.get_event_loop()
            output = await loop.run_in_executor(
                None,
                lambda: self.replicate_client.run(
                    model,
                    input=input_params
                )
            )
            
            output_str = str(output) if output else "None"
            logger.info(f"‚úÖ –°—Ü–µ–Ω–∞ {scene_number}: –§–æ—Ç–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ!")
            logger.info(f"   URL: {output_str[:80]}...")
            
            return {
                "status": "success",
                "photo_url": output_str,
                "model": model,
                "scene_number": scene_number
            }
            
        except Exception as e:
            logger.error(f"‚ùå –°—Ü–µ–Ω–∞ {scene_number}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ!")
            logger.error(f"   –û—à–∏–±–∫–∞: {str(e)}")
            logger.error(f"   –¢–∏–ø: {type(e).__name__}")
            import traceback
            logger.error(f"   Traceback: {traceback.format_exc()}")
            return {
                "status": "error",
                "error": str(e),
                "model": model,
                "scene_number": scene_number
            }